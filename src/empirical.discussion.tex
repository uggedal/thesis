\section{Discussion}

This section will discuss our various research questions in relation
to the results we have presented. We'll start with looking at
several aspects of activity streams as a social navigation
mechanism before we discuss prototyping with Greasemonkey on
an established web site.

When presenting our results we worked with a level of significance
$\alpha$ of $p \leq 0.05$%
\sidenote{
  See \sectionref{empirical.method.data.analysis.level.of.significance}
  for details.
}
and handled values of $p$ in a black and white fashion.
\prequote[\p{1277}]{rosnow89}{argues that}{%
  surely, God loves the .06 nearly as much as the .05}
We are therefore going to discuss results with values of $p$ approaching
$\alpha$ in a more flexible fashion in this section.

Based on our profiling of the respondents (see 
\tablepageref{respondents.profile.usage} for details)
we found the two groups which were using our implementation to be
representative of the general sample in all aspects except how
frequent they used \urort{}. The control group used \urort{} more
frequent than than both the general sample and the experiment group
with a probability of 0.055 compared to the general sample.
We argue that this makes the control group more experienced
\urort{} users than the experiment group.
This is an important aspect which we'll try to keep in mind in
the discussion about activity streams which follows.

\subsection{%
  Can social navigation trough activity streams help users keep
  up-to-date on favorites' activities on \urort{}?
}

We hypothesized that usage of activity streams would improve the level
of which participants could keep up-to-date on what their favorites
on \urort{} were doing.

\subsubsection{Activities in general}

Comparing how easy respondents felt it was to keep up-to-date on activities
within the experiment and control group%
\sidenote{
  See \tablepageref{uptodate.favorite.activities.within} for details.
}
we observed a higher increase in agreement for the experiment group. The
increase of agreement for the control group could be explained as
a placebo effect.
Since the probability of making a type I error are
$p = 0.086$ we simply take this result as an indication and not as hard proof
for validating our alternative hypothesis.

In addition the comparison within
groups we also compared the differences between the two groups. We observed
similar positive results for activity streams with $p$ approaching $\alpha$
with 0.089.
We take the higher increase of agreement for the experiment
group as an indication of the appropriateness of an activity stream for keeping
up to date on activities. We will not generalize these results to say that
activity streams are uniformly appropriate for keeping up-to-date on
favorites.

\subsubsection{Specific activities}

When asking participants to qualify more specific statements of how
easy they felt they could keep up-to-date on different types of activities
we observed differences between%
\sidenote{
  See
  \tablepageref{uptodate.favorite.specific.activities.between}
  for details.
}
the groups and within the groups%
\sidenote[2]{
  See
  \tablepageref{uptodate.favorite.specific.activities.within}
  for details.
}.
The between group data showed no significant nor borderline significant
differences between groups. This contradicts the borderline significant
results we found with the same comparison on activities in general.
When comparing within groups the only notable and significant difference
appeared for activities relating to publishing new blog posts.

Why do users of activity streams so strongly feel that the stream help them to
better keep up-to-date on recent blog posts and not the other types of
activities? One possible explanation could be that the activity stream
shows an excerpt of blog posts after the blog author and title.%
\sidenote{
  The activity stream with excerpts can be seen in
  \figurepageref{scrsh.urort.activity.stream}.
}
This means
that the user can get a glimpse into the content of the blog post without
actually navigating to the post itself.
But reviews from other users are also displayed with an excerpt of its
content. We therefore find this explanation to be highly suggestive.

Our data shows no indicators as why we experienced contradicting results
when asking how easy users could keep up-to date on activities in general
compared to specific activities. We note this as a potentially useful lesson
when conducting questions about the ease of conducting a task. In our case
asking more generally gave larger differences than asking more specific
questions.

\subsubsection{Perceived usefulness}

We tried to characterize in what way activity streams could be better than
no such feature for keeping up-to-date on favorites by asking respondents
to gauge statements of perceived usefulness.%
\sidenote{
  The results are available in
  \tablepageref{uptodate.favorite.perceived.usefulness.between}.
}
The results of asking in this manner yielded no noticeable nor significant
differences between experiment and control respondents. Similarly to asking
for specific activities, asking for specific qualities of keeping up-to-date
seems to result in only minor differences between groups.

\subsubsection{Perceived ease of use}

Our investigation into the perceived ease of use%
\sidenote{
  The results are available in
  \tablepageref{uptodate.favorite.perceived.ease.of.use.between}.
}
showed only minor differences between experiment and control groups. On the
issue of how flexible the prototype was respondents from the control group
actually reported higher acceptance to our statements.

We think the reason for
this lies in the nature of asking respondents about ease of use without
mentioning for what task the prototype should be easy to use. Our placebo
prototype had fewer features (lacking activity streams) and was more simple
than the experiment prototype with an activity stream. Surely the simplest
application would be easier to use as there are less information and less
navigational possibilities available. The statements of perceived ease of use
investigates the overall ease of using the application, not how easy it to use
for keeping up-to-date on activities. They measure technological acceptance
and not actual acceptance of the application to perform a particular task.

\subsubsection{Acceptance as standard feature}

Relating to perceived ease of use and technological acceptance is our question
about whether respondents wanted the prototype to be a standard feature
on \urort{}. The results%
\sidenote{
  \tablepageref{uptodate.standard.feature.between}
  lists the results.
}
indicated a dead race between the prototype with an activity feed and the
prototype without. While this data does not show a higher acceptance of
activity feeds its interesting to not how high the acceptance are for
our respondents. Even the placebo\dash{}composed of only a list of
a user's favorites\dash{}seems to be so useful for respondents that they want
it included together with \urort{}'s standard features.

\subsection{%
  Does social navigation trough activity streams lead users to more often keep
  up-to-date on favorites' activities on \urort{}?
}

\subsubsection{Keeping up-to-date frequency}

As we indicated in the beginning of our discussion the control respondents
seemed more experienced with using \urort{}. This is evident in how
frequent they keep up to date compared to experiment respondents for the
posttest.%
\sidenote{
  See
  \tablepageref{uptodate.favorite.activities.frequency.between}
  for details.
}
The control group's more frequent action of keeping up-to-date is highly
significant. When we compared the shift in the frequency of keeping up-to-date
from the pretest to the posttest%
\sidenote{
  See
  \tablepageref{uptodate.favorite.activities.frequency.within}
  for details.
}
we notice that the control group's frequency is practically unchanged.
Interestingly the experiment respondents frequency of keeping up-to-date have
increased significantly over the same period. This is a good example
of how our pretest and posttest experiment design have enabled us to look
at change over time within groups without jumping to inconclusive inferences
by looking only at the state after the treatment or placebo was introduced.

\subsubsection{Activity streams for keeping up-to-date on favorites}

Based on our data we've seen that its still unconclusive whether activity
streams help users in keeping up-to-date on activities. There seem to be an
indication of the usefulness of activity streams in this regard.
Activity streams clearly makes the task of keeping up with blog posts on
\urort{} easier.

We've seen how
one asks respondents questions can make a difference in the results one
are able to obtain. In our case more specific questions yielded answers
further from where we believed them to be based on our hypothese. A more
general question resulted in data more in line with our expectations.

\subsubsection{Prototype usage frequency}

Our data concerning how often the prototype was used between the two groups%
\sidenote{
  See
  \tablepageref{uptodate.prototype.frequency.between}
  for details.
}
are different than our findings of how often the same groups kept up-to-date
on favorites' activities. The prototype usage data showed that the experiment
group had a higher usage rate of \latest{} than the control respondents. The
results approaches $\alpha$ with $p = 0.056$.

Does this mean that these two data sources contradict eachother? Not
necessarily. The first frequency of use statistics shows how often the two
groups kept up-to-date on activities while the second shows how often
the two groups used our prototype. We believe the lower control group usage of
the prototype is related to the lower usefulness of the placebo
implementation.

Why do the control group then report higher frequencies for keeping up-to-date
on activities? There could be several reasons, but we believe this could
indicate that the control grup are keeping up-to-date on favorites' activities
with other means than the placebo prototype implementation. This could then
indicate that the placebo prototype without an activity stream is less useful
for keeping up-to-date on activities.

\subsubsection{Keeping up-to-date more often with activity streams}

To summarize, we believe that an activity stream makes respondents
more often keep up-to-date on activities than without. Those having used such
a tool reported larger changes over time in how frequent they conducted such
tasks than those which did not.

\subsection{%
  Does social navigation trough activity streams lead users to make
  more artists on \urort{} their favorites?
}

\subsection{%
  Can navigational prototyping with Greasemonkey be considered a
  viable technical option when testing user behavior in an
  established web site?
}

When we conducted a study of our prototype with real world users
we got valuable feedback on how well such a system works for the average
user.

\subsubsection{Limited in browser selection}

% Reference how many we had to send mail to and how many answered.
% Reference firefox usage for respondents to remove those respondents
% which did not actively use firefox from the above equation.

\subsubsection{Difficulties with installing Greasemonkey and user-scripts}

% reference non accomplish rates
% reference follow-up results (but take with a grain of salt)

\parabreak

During our development of a prototype application with Greasemonkey for
enhancing an established web page we got a feel for its pros and cons from a
development perspective.

\subsubsection{Requires no access to the established implementation}

\subsubsection{Requires little knowledge of the established implementation}

\subsubsection{Requires more work than altering the established
  implementation}

\subsubsection{Fragile when the established implementation is changed}
% Only happened once during a two month span on \urort{}. What was scary
% thought was that the changes made the user script on the client side
% obsolete. If this had happened under production usage when the user scripts
% was pushed to the clients we would be in a world of trouble. Changes on the
% server side platform can be handled more transparently.

\subsubsection{Less performant than the established implementation}

\section{Generalizability and Validity}

\subsection{Scale of experiment}

% small number of participants

\subsection{Selection of subjects}

% We were only concerned with Firefox users. These are probably
% not representative for Urørt users.

\subsection{Technical seeding}

% The installation process was somewhat complicated. This means
% that the most technically knowledgeable people are those
% which answered our posttests.

\subsection{Motive for participation}

% The people who want to participate in such an elaborate study is
% probably fairly interested in Urørt. They are experienced Urørt users
% and are therefore not representative of the Urørt population.

\subsection{Implications}

% This has consequences for the validity of our study. We can not generalize
% back to Urørt users in general.
